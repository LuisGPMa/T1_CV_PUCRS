{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "# Load the Haar Cascade XML file for face detection\n",
    "face_cascade = cv2.CascadeClassifier(r'haar_xml\\raw.githubusercontent.com_opencv_opencv_master_data_haarcascades_haarcascade_frontalface_default.xml')\n",
    "eyes_cascade = cv2.CascadeClassifier(r'haar_xml\\haarcascade_eye.xml')\n",
    "\n",
    "def get_intraocular_distance_in_pixels(lefteye, righteye):\n",
    "    leftx, lefty = lefteye[0]+lefteye[2]/2, lefteye[1]+lefteye[3]/2\n",
    "    point1 = np.array((leftx,lefty))\n",
    "    rightx, righty = righteye[0]+righteye[2]/2, righteye[1]+righteye[3]/2\n",
    "    point2 = np.array((rightx,righty))\n",
    "    dist = np.sqrt(np.sum(np.square(point1-point2)))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_keep_aspect_ratio(image, length_of_largest_dim=300, interpolation=cv2.INTER_AREA):\n",
    "    if image.shape[1]>=image.shape[0]:\n",
    "        ratio = image.shape[0]/image.shape[1]\n",
    "        dim = (length_of_largest_dim, int(length_of_largest_dim*ratio))\n",
    "    else:\n",
    "        ratio = image.shape[1]/image.shape[0]\n",
    "        dim = (int(length_of_largest_dim*ratio), length_of_largest_dim)\n",
    "    return cv2.resize(image, dim, interpolation = interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_eye_width = 35\n",
    "templates = [cv2.imread(rf'iris_templates\\{img_file}') for img_file in os.listdir('iris_templates')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sem_preprocessamento(img):\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessamento1(img):\n",
    "    img = resize_keep_aspect_ratio(img, length_of_largest_dim=300) #resize mantendo ratio entre lados\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converte pra grayscale\n",
    "    img = cv2.GaussianBlur(img,(3,3), sigmaX=33, sigmaY=33) #aplica blur gaussiano\n",
    "    return img\n",
    "# preprocessamento1(cv2.imread(r'data\\Natalie Portman\\069_c9e3207d.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessamento2(img):\n",
    "    # img = resize_keep_aspect_ratio(img, length_of_largest_dim=512) #tamanho original\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converte pra grayscale\n",
    "    # img = cv2.GaussianBlur(img,(3,3), sigmaX=33, sigmaY=33) #sem blur gaussiano\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessamento3(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converte pra grayscale\n",
    "    img = cv2.bilateralFilter(img,5,50,50) #blur bilateral\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['cv2.TM_SQDIFF']\n",
    "eye_over_face_ratio = 50/315\n",
    "for person in os.listdir('data'):\n",
    "    for img_file in os.listdir(f'data\\{person}'):\n",
    "        image = cv2.imread(rf'data\\{person}\\{img_file}')\n",
    "        image = preprocessamento2(image)\n",
    "        faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            # cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            roi = image[y:y+h, x:x+w]\n",
    "            # resized_face = cv2.resize(roi, (150,150), interpolation = cv2.INTER_AREA)\n",
    "            # cv2.imshow('Image with Detected Faces', image)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            # roi_gray = gray_image[y:y+h, x:x+w]\n",
    "            tolerance = .1\n",
    "        eyes = eyes_cascade.detectMultiScale(roi, minNeighbors=2, minSize=(int(roi.shape[0]*(eye_over_face_ratio*(1-tolerance))),int(roi.shape[1]*(eye_over_face_ratio*(1-tolerance)))), maxSize=(int(roi.shape[0]*(eye_over_face_ratio*(1+tolerance))),int(roi.shape[1]*(eye_over_face_ratio*(1+tolerance)))))\n",
    "\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            roi_eye = roi[ey:ey+eh, ex:ex+ew]\n",
    "            eye_over_template_ratio = ew/templates[0].shape[0]\n",
    "            iris_over_eye_ratio = 0.31\n",
    "            # cv2.rectangle(image,(ex+x,ey+y),(ex+ew+x,ey+eh+y),(0,255,0),2)\n",
    "            \n",
    "            # cv2.imshow('Image with Detected Faces', image)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            for idx,template in enumerate(templates):\n",
    "                template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY) #converte template pra grayscale\n",
    "                new_template_shape = (int(template.shape[0]*eye_over_template_ratio*iris_over_eye_ratio),int(template.shape[1]*eye_over_template_ratio*iris_over_eye_ratio))\n",
    "                resized_template = cv2.resize(template, new_template_shape, interpolation = cv2.INTER_AREA)\n",
    "                tw, th = resized_template.shape[::-1]\n",
    "                \n",
    "                for meth in methods:\n",
    "                    method = eval(meth)\n",
    "                    # Apply template Matching\n",
    "                    res = cv2.matchTemplate(roi_eye,resized_template,method)\n",
    "                    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "                    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "                    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "                        top_left = min_loc\n",
    "                    else:\n",
    "                        top_left = max_loc\n",
    "                    bottom_right = (top_left[0] + tw, top_left[1] + th)\n",
    "                    roi_rec = roi_eye.copy()\n",
    "                    cv2.rectangle(roi_rec,top_left, bottom_right, 255, 2)\n",
    "\n",
    "                    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "                    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "                    plt.subplot(122),plt.imshow(roi_rec,cmap = 'gray')\n",
    "                    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "                    plt.suptitle(f'Template {idx+1}')\n",
    "                    plt.show()\n",
    "\n",
    "                # x_offset=y_offset=0\n",
    "                # roi_eye[y_offset:y_offset+resized_template.shape[0], x_offset:x_offset+resized_template.shape[1]] = resized_template\n",
    "                \n",
    "            # cv2.imshow('Image with Detected Faces', res)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            # cv2.imshow('Image with Detected Faces', roi_eye)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            # loc = np.where(res >= threshold)\n",
    "            # tw, th = template.shape[::-1]\n",
    "            # for pt in zip(*loc[::-1]):\n",
    "                # cv2.rectangle(roi_eye, pt, (pt[0] + tw, pt[1] + th), (255, 255, 255), 2)\n",
    "            \n",
    "            #cv2.rectangle(image,(ex+x,ey+y),(ex+ew+x,ey+eh+y),(0,255,0),2)\n",
    "                # cv2.imshow('Image with Detected Faces', res)\n",
    "                # cv2.waitKey(0)\n",
    "                # cv2.destroyAllWindows()\n",
    "        # cv2.imshow('Image with Detected Faces', image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "# [44,44,30,32,29,25,35,31,36,38,37,37,29,28,34,36,42,41,41,43,43,44,41,42,35,31,34,30,24,31,33,31,26,24,36,30,35,36,38,41]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipe1temp1 0.5813953488372093\n",
      "pipe1temp2 0.0\n",
      "pipe1temp3 0.5581395348837209\n",
      "pipe1temp4 0.11627906976744186\n",
      "sem preproc temp1 0.6666666666666666\n",
      "sem preproc temp2 0.0\n",
      "sem preproc temp3 0.5\n",
      "sem preproc temp4 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "resultados_pipe_1 = [0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,1,0,1,1,1,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,1,1,0,0,1,1]\n",
    "resultados_pipe_1_template_1 = resultados_pipe_1[::4]\n",
    "resultados_pipe_1_template_2 = resultados_pipe_1[1::4]\n",
    "resultados_pipe_1_template_3 = resultados_pipe_1[2::4]\n",
    "resultados_pipe_1_template_4 = resultados_pipe_1[3::4]\n",
    "pipe1_temp1_acc = np.count_nonzero(resultados_pipe_1_template_1)/len(resultados_pipe_1_template_1)\n",
    "pipe1_temp2_acc = np.count_nonzero(resultados_pipe_1_template_2)/len(resultados_pipe_1_template_2)\n",
    "pipe1_temp3_acc = np.count_nonzero(resultados_pipe_1_template_3)/len(resultados_pipe_1_template_3)\n",
    "pipe1_temp4_acc = np.count_nonzero(resultados_pipe_1_template_4)/len(resultados_pipe_1_template_4)\n",
    "print('pipe1temp1',pipe1_temp1_acc)\n",
    "print('pipe1temp2',pipe1_temp2_acc)\n",
    "print('pipe1temp3',pipe1_temp3_acc)\n",
    "print('pipe1temp4',pipe1_temp4_acc)\n",
    "\n",
    "resultados_sem_preproc = [0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,1,0,]\n",
    "resultados_sem_preproc_template_1 = resultados_sem_preproc[::4]\n",
    "resultados_sem_preproc_template_2 = resultados_sem_preproc[1::4]\n",
    "resultados_sem_preproc_template_3 = resultados_sem_preproc[2::4]\n",
    "resultados_sem_preproc_template_4 = resultados_sem_preproc[3::4]\n",
    "sem_preproc_temp1_acc = np.count_nonzero(resultados_sem_preproc_template_1)/len(resultados_sem_preproc_template_1)\n",
    "sem_preproc_temp2_acc = np.count_nonzero(resultados_sem_preproc_template_2)/len(resultados_sem_preproc_template_2)\n",
    "sem_preproc_temp3_acc = np.count_nonzero(resultados_sem_preproc_template_3)/len(resultados_sem_preproc_template_3)\n",
    "sem_preproc_temp4_acc = np.count_nonzero(resultados_sem_preproc_template_4)/len(resultados_sem_preproc_template_4)\n",
    "print('sem preproc temp1', sem_preproc_temp1_acc)\n",
    "print('sem preproc temp2', sem_preproc_temp2_acc)\n",
    "print('sem preproc temp3', sem_preproc_temp3_acc)\n",
    "print('sem preproc temp4', sem_preproc_temp4_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sem preproc temp1 0.6388888888888888\n",
      "sem preproc temp2 0.0\n",
      "sem preproc temp3 0.5277777777777778\n",
      "sem preproc temp4 0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "resultados_pipe_3 = [0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,1,0,1,0,0,0,1,1,0,0,0,0]\n",
    "resultados_pipe_3_template_1 = resultados_pipe_3[::4]\n",
    "resultados_pipe_3_template_2 = resultados_pipe_3[1::4]\n",
    "resultados_pipe_3_template_3 = resultados_pipe_3[2::4]\n",
    "resultados_pipe_3_template_4 = resultados_pipe_3[3::4]\n",
    "pipe_3_temp1_acc = np.count_nonzero(resultados_pipe_3_template_1)/len(resultados_pipe_3_template_1)\n",
    "pipe_3_temp2_acc = np.count_nonzero(resultados_pipe_3_template_2)/len(resultados_pipe_3_template_2)\n",
    "pipe_3_temp3_acc = np.count_nonzero(resultados_pipe_3_template_3)/len(resultados_pipe_3_template_3)\n",
    "pipe_3_temp4_acc = np.count_nonzero(resultados_pipe_3_template_4)/len(resultados_pipe_3_template_4)\n",
    "print('sem preproc temp1', pipe_3_temp1_acc)\n",
    "print('sem preproc temp2', pipe_3_temp2_acc)\n",
    "print('sem preproc temp3', pipe_3_temp3_acc)\n",
    "print('sem preproc temp4', pipe_3_temp4_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_center(eye):\n",
    "    x,y,w,h = eye\n",
    "    eye_center = (x + w//2, y + h//2)\n",
    "    return eye_center\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
